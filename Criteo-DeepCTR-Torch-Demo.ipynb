{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9d71b4f",
   "metadata": {},
   "source": [
    "# Criteo Click-Through Rate (CTR) Predciton\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee98ba8",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "  <img src=\"images/Criteo-Logo-Orange.png\" alt=\"criteo-logo\" width=500 />\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5637bf",
   "metadata": {},
   "source": [
    "## What is Click-Through Rate (CTR)?\n",
    "\n",
    "**Click-Through Rate (CTR)** is a key metric in online advertising.\n",
    "\n",
    "$$\n",
    "CTR = \\frac{\\text{Clicks}}{\\text{Impressions}} \\times 100\\%\n",
    "$$\n",
    "\n",
    "- **Clicks** -> how many times users clicked on the ad\n",
    "- **Impressions** -> how many times the ad was shown\n",
    "\n",
    "The **CTR prediction task** focuses on modeling the _likelihood of a click_ based on:\n",
    "\n",
    "- Ad characteristics (e.g., text, image, placement)\n",
    "- User profile data (e.g., demographics, behavior)\n",
    "- Contextual features (e.g., time of day, device, location)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1edee9ed",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ed44db",
   "metadata": {},
   "source": [
    "### Data Dictionary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb0465b",
   "metadata": {},
   "source": [
    "- **label (int64):** Target variable that indicates if an ad was clicked (1) or not (0).\n",
    "- **I1-I13 (float64 | int64):** A total of 13 columns of integer features (mostly count features).\n",
    "- **C1-C26 (object):** A total of 26 columns of categorical features. The values of these features have been hashed onto 32 bits for anonymization purposes.\n",
    "\n",
    "Data is obtained from: https://www.kaggle.com/datasets/mrkmakr/criteo-dataset?resource=download\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de843f44",
   "metadata": {},
   "source": [
    "### Criteo Data (45M)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b880dff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af93b854",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_columns = (\n",
    "#     [\"label\"] + [f\"I{i}\" for i in range(1, 14)] + [f\"C{i}\" for i in range(1, 27)]\n",
    "# )\n",
    "# test_columns = [f\"I{i}\" for i in range(1, 14)] + [f\"C{i}\" for i in range(1, 27)]\n",
    "\n",
    "# criteo_train = pd.read_csv(\n",
    "#     \"data/criteo_kaggle/train.csv\", header=None, sep=\"\\t\", names=train_columns\n",
    "# )\n",
    "# criteo_test = pd.read_csv(\n",
    "#     \"data/criteo_kaggle/test.csv\", header=None, sep=\"\\t\", names=test_columns\n",
    "# )\n",
    "\n",
    "# print(f\"Criteo train dataset has shape: {criteo_train.shape}\")\n",
    "# print(f\"Criteo test dataset has shape: {criteo_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94745c94",
   "metadata": {},
   "source": [
    "Train dataset has shape: (45840617, 40) -> 45M entries, 39 features, 1 label\n",
    "\n",
    "Test dataset has shape: (6042135, 39) -> 6M entries, 39 features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2e4067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# criteo_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46cc27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_missing_values = criteo_train.isnull().sum()\n",
    "\n",
    "# train_missing_df = pd.DataFrame(\n",
    "#     {\n",
    "#         \"Feature\": train_missing_values.index,\n",
    "#         \"Missing Count\": train_missing_values.values,\n",
    "#         \"Missing Percentage\": (train_missing_values / len(criteo_train) * 100).round(2),\n",
    "#     }\n",
    "# )\n",
    "\n",
    "# train_missing_df = train_missing_df.sort_values(\"Missing Count\", ascending=False)\n",
    "# train_missing_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f84f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# criteo_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0634c5",
   "metadata": {},
   "source": [
    "### Criteo - Training Data Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68cdd4c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CRITEO: Train pool shape: (45440617, 40)\n",
      "CRITEO: Test pool shape: (400000, 40)\n",
      "CRITEO: Train data shape: (1000000, 40)\n",
      "CRITEO: Test data shape: (200000, 40)\n",
      "CRITEO: Train data saved to data\\criteo_kaggle\\criteo_train_20251212_1655_1000000.csv\n",
      "CRITEO: Test data saved to data\\criteo_kaggle\\criteo_test_20251212_1655_200000.csv\n"
     ]
    }
   ],
   "source": [
    "from src.utils.data_utils import criteo_sample_data\n",
    "\n",
    "criteo_train, criteo_test = criteo_sample_data(\n",
    "    data_path=\"data/criteo_kaggle/train.csv\",\n",
    "    use_sklearn_split=False,\n",
    "    train_sample_size=1_000_000,\n",
    "    test_sample_size=200_000,\n",
    "    save=True,\n",
    "    seed=1773,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc699cff",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c8a3dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from deepctr_torch.inputs import SparseFeat, DenseFeat, get_feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b478810b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_features = [\"C\" + str(i) for i in range(1, 27)]\n",
    "dense_features = [\"I\" + str(i) for i in range(1, 14)]\n",
    "target = [\"label\"]\n",
    "\n",
    "# Dense feature missing imputation --- maybe need more inspection\n",
    "for col in dense_features:\n",
    "    if col in criteo_train.columns:\n",
    "        criteo_train[col] = criteo_train[col].fillna(0)\n",
    "    if col in criteo_test.columns:\n",
    "        criteo_test[col] = criteo_test[col].fillna(0)\n",
    "\n",
    "# Categorical feature missing imputation --- need string here\n",
    "for col in sparse_features:\n",
    "    if col in criteo_train.columns:\n",
    "        criteo_train[col] = criteo_train[col].fillna(\"UNKNOWN\")\n",
    "    if col in criteo_test.columns:\n",
    "        criteo_test[col] = criteo_test[col].fillna(\"UNKNOWN\")\n",
    "\n",
    "# Label Encoding for sparse features\n",
    "for feat in sparse_features:\n",
    "    lbe = LabelEncoder()\n",
    "    criteo_train[feat] = lbe.fit_transform(criteo_train[feat])\n",
    "    criteo_test[feat] = lbe.fit_transform(criteo_test[feat])\n",
    "\n",
    "# Simple Transformation for dense features\n",
    "mms = MinMaxScaler(feature_range=(0, 1))\n",
    "criteo_train[dense_features] = mms.fit_transform(criteo_train[dense_features])\n",
    "criteo_test[dense_features] = mms.fit_transform(criteo_test[dense_features])\n",
    "\n",
    "# Count #unique features for each sparse field,and record dense feature field name\n",
    "fixlen_feature_columns = [\n",
    "    SparseFeat(feat, vocabulary_size=criteo_train[feat].nunique(), embedding_dim=4)\n",
    "    for i, feat in enumerate(sparse_features)\n",
    "] + [\n",
    "    DenseFeat(\n",
    "        feat,\n",
    "        1,\n",
    "    )\n",
    "    for feat in dense_features\n",
    "]\n",
    "\n",
    "dnn_feature_columns = fixlen_feature_columns\n",
    "linear_feature_columns = fixlen_feature_columns\n",
    "\n",
    "feature_names = get_feature_names(linear_feature_columns + dnn_feature_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6cf37b7",
   "metadata": {},
   "source": [
    "## Model Training and Evaluation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc6afbf",
   "metadata": {},
   "source": [
    "### Performance Metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e415b07e",
   "metadata": {},
   "source": [
    "$$BCELoss = L(y, \\hat{y}) = -\\frac{1}{N}\\sum_{i=1}^{N} [y_i \\log(\\hat{y}_i) + (1-y_i) \\log(1-\\hat{y}_i)]$$\n",
    "\n",
    "$$\n",
    "\\mathrm{AUC} = \\int_{0}^{1} \\mathrm{TPR}(t) \\, d(\\mathrm{FPR}(t))\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a389cb17",
   "metadata": {},
   "source": [
    "### DeepFM (DeepCTR-Torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ad7650e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.metrics import log_loss, roc_auc_score\n",
    "from deepctr_torch.models import DeepFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0b610787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch: Cuda ready, device=cuda:0\n",
      "cuda:0\n",
      "Train on 800000 samples, validate on 200000 samples, 50 steps per epoch\n",
      "Epoch 1/30\n",
      "8s - loss:  0.5818 - binary_crossentropy:  0.5818 - val_binary_crossentropy:  0.5179\n",
      "Epoch 2/30\n",
      "7s - loss:  0.4744 - binary_crossentropy:  0.4744 - val_binary_crossentropy:  0.4905\n",
      "Epoch 3/30\n",
      "7s - loss:  0.3855 - binary_crossentropy:  0.3855 - val_binary_crossentropy:  0.5393\n",
      "Epoch 4/30\n",
      "7s - loss:  0.3214 - binary_crossentropy:  0.3214 - val_binary_crossentropy:  0.5502\n",
      "Epoch 5/30\n",
      "7s - loss:  0.2989 - binary_crossentropy:  0.2989 - val_binary_crossentropy:  0.5636\n",
      "Epoch 6/30\n",
      "7s - loss:  0.2884 - binary_crossentropy:  0.2884 - val_binary_crossentropy:  0.5679\n",
      "Epoch 7/30\n",
      "7s - loss:  0.2823 - binary_crossentropy:  0.2823 - val_binary_crossentropy:  0.5732\n",
      "Epoch 8/30\n",
      "7s - loss:  0.2784 - binary_crossentropy:  0.2784 - val_binary_crossentropy:  0.5791\n",
      "Epoch 9/30\n",
      "7s - loss:  0.2752 - binary_crossentropy:  0.2752 - val_binary_crossentropy:  0.5827\n",
      "Epoch 10/30\n",
      "6s - loss:  0.2724 - binary_crossentropy:  0.2724 - val_binary_crossentropy:  0.5904\n",
      "Epoch 11/30\n",
      "6s - loss:  0.2702 - binary_crossentropy:  0.2702 - val_binary_crossentropy:  0.5974\n",
      "Epoch 12/30\n",
      "6s - loss:  0.2683 - binary_crossentropy:  0.2683 - val_binary_crossentropy:  0.6006\n",
      "Epoch 13/30\n",
      "6s - loss:  0.2667 - binary_crossentropy:  0.2667 - val_binary_crossentropy:  0.6024\n",
      "Epoch 14/30\n",
      "6s - loss:  0.2648 - binary_crossentropy:  0.2648 - val_binary_crossentropy:  0.6056\n",
      "Epoch 15/30\n",
      "6s - loss:  0.2631 - binary_crossentropy:  0.2631 - val_binary_crossentropy:  0.6119\n",
      "Epoch 16/30\n",
      "6s - loss:  0.2617 - binary_crossentropy:  0.2617 - val_binary_crossentropy:  0.6180\n",
      "Epoch 17/30\n",
      "6s - loss:  0.2595 - binary_crossentropy:  0.2595 - val_binary_crossentropy:  0.6207\n",
      "Epoch 18/30\n",
      "7s - loss:  0.2579 - binary_crossentropy:  0.2579 - val_binary_crossentropy:  0.6279\n",
      "Epoch 19/30\n",
      "7s - loss:  0.2563 - binary_crossentropy:  0.2563 - val_binary_crossentropy:  0.6360\n",
      "Epoch 20/30\n",
      "7s - loss:  0.2547 - binary_crossentropy:  0.2547 - val_binary_crossentropy:  0.6395\n",
      "Epoch 21/30\n",
      "8s - loss:  0.2524 - binary_crossentropy:  0.2524 - val_binary_crossentropy:  0.6470\n",
      "Epoch 22/30\n",
      "7s - loss:  0.2507 - binary_crossentropy:  0.2507 - val_binary_crossentropy:  0.6536\n",
      "Epoch 23/30\n",
      "7s - loss:  0.2486 - binary_crossentropy:  0.2486 - val_binary_crossentropy:  0.6637\n",
      "Epoch 24/30\n",
      "7s - loss:  0.2467 - binary_crossentropy:  0.2467 - val_binary_crossentropy:  0.6698\n",
      "Epoch 25/30\n",
      "7s - loss:  0.2444 - binary_crossentropy:  0.2444 - val_binary_crossentropy:  0.6842\n",
      "Epoch 26/30\n",
      "7s - loss:  0.2426 - binary_crossentropy:  0.2426 - val_binary_crossentropy:  0.6909\n",
      "Epoch 27/30\n",
      "7s - loss:  0.2408 - binary_crossentropy:  0.2408 - val_binary_crossentropy:  0.7016\n",
      "Epoch 28/30\n",
      "7s - loss:  0.2384 - binary_crossentropy:  0.2384 - val_binary_crossentropy:  0.7165\n",
      "Epoch 29/30\n",
      "7s - loss:  0.2363 - binary_crossentropy:  0.2362 - val_binary_crossentropy:  0.7196\n",
      "Epoch 30/30\n",
      "7s - loss:  0.2340 - binary_crossentropy:  0.2340 - val_binary_crossentropy:  0.7371\n"
     ]
    }
   ],
   "source": [
    "train_model_input = {name: criteo_train[name] for name in feature_names}\n",
    "test_model_input = {name: criteo_test[name] for name in feature_names}\n",
    "\n",
    "use_cuda = True\n",
    "if use_cuda and torch.cuda.is_available():\n",
    "    device = \"cuda:0\"\n",
    "    print(f\"PyTorch: Cuda ready, device={device}\")\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "model = DeepFM(\n",
    "    linear_feature_columns=linear_feature_columns,\n",
    "    dnn_feature_columns=dnn_feature_columns,\n",
    "    dnn_hidden_units=(128, 128, 64),\n",
    "    task=\"binary\",\n",
    "    l2_reg_embedding=1e-5,\n",
    "    device=device,\n",
    "    seed=1773,\n",
    ")\n",
    "model.compile(\"adam\", \"binary_crossentropy\", metrics=[\"binary_crossentropy\"])\n",
    "\n",
    "history = model.fit(\n",
    "    train_model_input,\n",
    "    criteo_train[target].values,\n",
    "    batch_size=16000,\n",
    "    epochs=30,\n",
    "    verbose=2,  # 0 for non, 1 for progress bar, 2 for every epoch\n",
    "    validation_split=0.2,  # was 0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0113da33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST: BCE Loss: 2.7475 | ROC AUC: 0.546 \n"
     ]
    }
   ],
   "source": [
    "pred_ans = model.predict(test_model_input, batch_size=256)\n",
    "\n",
    "print(\n",
    "    f\"TEST: BCE Loss: {round(log_loss(criteo_test[target].values, pred_ans), 4)} | ROC AUC: {round(roc_auc_score(criteo_test[target].values, pred_ans), 4)} \"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ctrpredenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
