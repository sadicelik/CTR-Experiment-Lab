{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9d71b4f",
   "metadata": {},
   "source": [
    "# Criteo Click-Through Rate (CTR) Predciton\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee98ba8",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "  <img src=\"../images/Criteo-Logo-Orange.png\" alt=\"criteo-logo\" width=500 />\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5637bf",
   "metadata": {},
   "source": [
    "## What is Click-Through Rate (CTR)?\n",
    "\n",
    "**Click-Through Rate (CTR)** is a key metric in online advertising.\n",
    "\n",
    "$$\n",
    "CTR = \\frac{\\text{Clicks}}{\\text{Impressions}} \\times 100\\%\n",
    "$$\n",
    "\n",
    "- **Clicks** -> how many times users clicked on the ad\n",
    "- **Impressions** -> how many times the ad was shown\n",
    "\n",
    "The **CTR prediction task** focuses on modeling the _likelihood of a click_ based on:\n",
    "\n",
    "- Ad characteristics (e.g., text, image, placement)\n",
    "- User profile data (e.g., demographics, behavior)\n",
    "- Contextual features (e.g., time of day, device, location)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1edee9ed",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ed44db",
   "metadata": {},
   "source": [
    "### Data Dictionary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb0465b",
   "metadata": {},
   "source": [
    "- **label (int64):** Target variable that indicates if an ad was clicked (1) or not (0).\n",
    "- **I1-I13 (float64 | int64):** A total of 13 columns of integer features (mostly count features).\n",
    "- **C1-C26 (object):** A total of 26 columns of categorical features. The values of these features have been hashed onto 32 bits for anonymization purposes.\n",
    "\n",
    "Data is obtained from: https://www.kaggle.com/datasets/mrkmakr/criteo-dataset?resource=download\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de843f44",
   "metadata": {},
   "source": [
    "### Criteo Data (45M)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b880dff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af93b854",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_columns = (\n",
    "#     [\"label\"] + [f\"I{i}\" for i in range(1, 14)] + [f\"C{i}\" for i in range(1, 27)]\n",
    "# )\n",
    "# test_columns = [f\"I{i}\" for i in range(1, 14)] + [f\"C{i}\" for i in range(1, 27)]\n",
    "\n",
    "# criteo_train = pd.read_csv(\n",
    "#     \"data/criteo_kaggle/train.csv\", header=None, sep=\"\\t\", names=train_columns\n",
    "# )\n",
    "# criteo_test = pd.read_csv(\n",
    "#     \"data/criteo_kaggle/test.csv\", header=None, sep=\"\\t\", names=test_columns\n",
    "# )\n",
    "\n",
    "# print(f\"Criteo train dataset has shape: {criteo_train.shape}\")\n",
    "# print(f\"Criteo test dataset has shape: {criteo_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94745c94",
   "metadata": {},
   "source": [
    "Train dataset has shape: (45840617, 40) -> 45M entries, 39 features, 1 label\n",
    "\n",
    "Test dataset has shape: (6042135, 39) -> 6M entries, 39 features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f2e4067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# criteo_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f46cc27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_missing_values = criteo_train.isnull().sum()\n",
    "\n",
    "# train_missing_df = pd.DataFrame(\n",
    "#     {\n",
    "#         \"Feature\": train_missing_values.index,\n",
    "#         \"Missing Count\": train_missing_values.values,\n",
    "#         \"Missing Percentage\": (train_missing_values / len(criteo_train) * 100).round(2),\n",
    "#     }\n",
    "# )\n",
    "\n",
    "# train_missing_df = train_missing_df.sort_values(\"Missing Count\", ascending=False)\n",
    "# train_missing_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01f84f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# criteo_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc699cff",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c8a3dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from deepctr_torch.inputs import SparseFeat, DenseFeat, get_feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b478810b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the Criteo data from ../data/criteo_kaggle/train.csv\n",
      "Encoding sparse features and transforming dense features...\n"
     ]
    }
   ],
   "source": [
    "sparse_features = [\"C\" + str(i) for i in range(1, 27)]\n",
    "dense_features = [\"I\" + str(i) for i in range(1, 14)]\n",
    "target = [\"label\"]\n",
    "criteo_features = target + dense_features + sparse_features\n",
    "\n",
    "criteo_path = \"../data/criteo_kaggle/train.csv\"\n",
    "print(f\"Loading the Criteo data from {criteo_path}\")\n",
    "criteo_data = pd.read_csv(criteo_path, header=None, sep=\"\\t\", names=criteo_features)\n",
    "\n",
    "criteo_data = criteo_data.sample(n=1_000_000, random_state=1773)\n",
    "\n",
    "# Categorical feature missing imputation --- need string here\n",
    "criteo_data[sparse_features] = criteo_data[sparse_features].fillna(\n",
    "    \"-1\",\n",
    ")\n",
    "# Dense feature missing imputation --- maybe need more inspection\n",
    "criteo_data[dense_features] = criteo_data[dense_features].fillna(\n",
    "    0,\n",
    ")\n",
    "\n",
    "# ----- Label Encoding for sparse features,and do simple Transformation for dense features ----- #\n",
    "\n",
    "print(f\"Encoding sparse features and transforming dense features...\")\n",
    "\n",
    "for feat in sparse_features:\n",
    "    lbe = LabelEncoder()\n",
    "    criteo_data[feat] = lbe.fit_transform(criteo_data[feat])\n",
    "\n",
    "mms = MinMaxScaler(feature_range=(0, 1))\n",
    "criteo_data[dense_features] = mms.fit_transform(criteo_data[dense_features])\n",
    "\n",
    "# ----- Count #unique features for each sparse field, and record dense feature field name ----- #\n",
    "\n",
    "fixlen_feature_columns = [\n",
    "    SparseFeat(\n",
    "        feat,\n",
    "        vocabulary_size=criteo_data[feat].max() + 1,\n",
    "        embedding_dim=4,\n",
    "    )\n",
    "    for feat in sparse_features\n",
    "] + [DenseFeat(feat, 1) for feat in dense_features]\n",
    "\n",
    "dnn_feature_columns = fixlen_feature_columns\n",
    "linear_feature_columns = fixlen_feature_columns\n",
    "\n",
    "feature_names = get_feature_names(linear_feature_columns + dnn_feature_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6cf37b7",
   "metadata": {},
   "source": [
    "## Model Training and Evaluation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc6afbf",
   "metadata": {},
   "source": [
    "### Performance Metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e415b07e",
   "metadata": {},
   "source": [
    "$$BCELoss = L(y, \\hat{y}) = -\\frac{1}{N}\\sum_{i=1}^{N} [y_i \\log(\\hat{y}_i) + (1-y_i) \\log(1-\\hat{y}_i)]$$\n",
    "\n",
    "$$\n",
    "\\mathrm{AUC} = \\int_{0}^{1} \\mathrm{TPR}(t) \\, d(\\mathrm{FPR}(t))\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a389cb17",
   "metadata": {},
   "source": [
    "### DeepFM (DeepCTR-Torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ad7650e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.metrics import log_loss, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from deepctr_torch.models import DeepFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b610787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch: Cuda ready, device=cuda:0\n",
      "cuda:0\n",
      "Train on 640000 samples, validate on 160000 samples, 40 steps per epoch\n",
      "Epoch 1/30\n",
      "5s - loss:  0.5905 - binary_crossentropy:  0.5905 - val_binary_crossentropy:  0.5362\n",
      "Epoch 2/30\n",
      "5s - loss:  0.4952 - binary_crossentropy:  0.4952 - val_binary_crossentropy:  0.4942\n",
      "Epoch 3/30\n",
      "6s - loss:  0.4176 - binary_crossentropy:  0.4176 - val_binary_crossentropy:  0.5199\n",
      "Epoch 4/30\n",
      "6s - loss:  0.3354 - binary_crossentropy:  0.3354 - val_binary_crossentropy:  0.5535\n",
      "Epoch 5/30\n",
      "5s - loss:  0.3004 - binary_crossentropy:  0.3004 - val_binary_crossentropy:  0.5683\n",
      "Epoch 6/30\n",
      "6s - loss:  0.2853 - binary_crossentropy:  0.2853 - val_binary_crossentropy:  0.5796\n",
      "Epoch 7/30\n",
      "5s - loss:  0.2775 - binary_crossentropy:  0.2775 - val_binary_crossentropy:  0.5855\n",
      "Epoch 8/30\n",
      "5s - loss:  0.2725 - binary_crossentropy:  0.2725 - val_binary_crossentropy:  0.5929\n",
      "Epoch 9/30\n",
      "5s - loss:  0.2685 - binary_crossentropy:  0.2685 - val_binary_crossentropy:  0.6003\n",
      "Epoch 10/30\n",
      "5s - loss:  0.2658 - binary_crossentropy:  0.2658 - val_binary_crossentropy:  0.6064\n",
      "Epoch 11/30\n",
      "5s - loss:  0.2634 - binary_crossentropy:  0.2634 - val_binary_crossentropy:  0.6134\n",
      "Epoch 12/30\n",
      "6s - loss:  0.2619 - binary_crossentropy:  0.2619 - val_binary_crossentropy:  0.6150\n",
      "Epoch 13/30\n",
      "5s - loss:  0.2598 - binary_crossentropy:  0.2598 - val_binary_crossentropy:  0.6197\n",
      "Epoch 14/30\n",
      "5s - loss:  0.2584 - binary_crossentropy:  0.2584 - val_binary_crossentropy:  0.6249\n",
      "Epoch 15/30\n",
      "5s - loss:  0.2572 - binary_crossentropy:  0.2571 - val_binary_crossentropy:  0.6285\n",
      "Epoch 16/30\n",
      "5s - loss:  0.2559 - binary_crossentropy:  0.2559 - val_binary_crossentropy:  0.6322\n",
      "Epoch 17/30\n",
      "5s - loss:  0.2550 - binary_crossentropy:  0.2550 - val_binary_crossentropy:  0.6329\n",
      "Epoch 18/30\n",
      "6s - loss:  0.2539 - binary_crossentropy:  0.2539 - val_binary_crossentropy:  0.6373\n",
      "Epoch 19/30\n",
      "5s - loss:  0.2527 - binary_crossentropy:  0.2527 - val_binary_crossentropy:  0.6427\n",
      "Epoch 20/30\n",
      "5s - loss:  0.2515 - binary_crossentropy:  0.2515 - val_binary_crossentropy:  0.6471\n",
      "Epoch 21/30\n",
      "5s - loss:  0.2511 - binary_crossentropy:  0.2510 - val_binary_crossentropy:  0.6515\n",
      "Epoch 22/30\n",
      "5s - loss:  0.2496 - binary_crossentropy:  0.2496 - val_binary_crossentropy:  0.6525\n",
      "Epoch 23/30\n",
      "5s - loss:  0.2482 - binary_crossentropy:  0.2482 - val_binary_crossentropy:  0.6631\n",
      "Epoch 24/30\n",
      "5s - loss:  0.2473 - binary_crossentropy:  0.2473 - val_binary_crossentropy:  0.6608\n",
      "Epoch 25/30\n",
      "5s - loss:  0.2458 - binary_crossentropy:  0.2458 - val_binary_crossentropy:  0.6714\n",
      "Epoch 26/30\n",
      "5s - loss:  0.2449 - binary_crossentropy:  0.2449 - val_binary_crossentropy:  0.6730\n",
      "Epoch 27/30\n",
      "5s - loss:  0.2434 - binary_crossentropy:  0.2434 - val_binary_crossentropy:  0.6761\n",
      "Epoch 28/30\n",
      "5s - loss:  0.2425 - binary_crossentropy:  0.2425 - val_binary_crossentropy:  0.6833\n",
      "Epoch 29/30\n",
      "5s - loss:  0.2410 - binary_crossentropy:  0.2410 - val_binary_crossentropy:  0.6908\n",
      "Epoch 30/30\n",
      "5s - loss:  0.2399 - binary_crossentropy:  0.2398 - val_binary_crossentropy:  0.6977\n"
     ]
    }
   ],
   "source": [
    "criteo_train, criteo_test = train_test_split(\n",
    "    criteo_data, test_size=0.2, random_state=1773\n",
    ")\n",
    "\n",
    "train_model_input = {name: criteo_train[name] for name in feature_names}\n",
    "test_model_input = {name: criteo_test[name] for name in feature_names}\n",
    "\n",
    "use_cuda = True\n",
    "if use_cuda and torch.cuda.is_available():\n",
    "    device = \"cuda:0\"\n",
    "    print(f\"PyTorch: Cuda ready, device={device}\")\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "model = DeepFM(\n",
    "    linear_feature_columns=linear_feature_columns,\n",
    "    dnn_feature_columns=dnn_feature_columns,\n",
    "    dnn_hidden_units=(128, 128, 64),\n",
    "    task=\"binary\",\n",
    "    l2_reg_embedding=1e-5,\n",
    "    device=device,\n",
    "    seed=1773,\n",
    ")\n",
    "model.compile(\"adam\", \"binary_crossentropy\", metrics=[\"binary_crossentropy\"])\n",
    "\n",
    "history = model.fit(\n",
    "    train_model_input,\n",
    "    criteo_train[target].values,\n",
    "    batch_size=16000,\n",
    "    epochs=30,\n",
    "    verbose=2,  # 0 for non, 1 for progress bar, 2 for every epoch\n",
    "    validation_split=0.2,  # was 0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0113da33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST: BCE Loss: 0.6933 | ROC AUC: 0.7001 \n"
     ]
    }
   ],
   "source": [
    "pred_ans = model.predict(test_model_input, batch_size=256)\n",
    "\n",
    "print(\n",
    "    f\"TEST: BCE Loss: {round(log_loss(criteo_test[target].values, pred_ans), 4)} | ROC AUC: {round(roc_auc_score(criteo_test[target].values, pred_ans), 4)} \"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ctrpredenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
