MODEL GENERATOR: PyTorch: MLP(
  (mlp): Sequential(
    (0): Linear(in_features=21, out_features=128, bias=True)
    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Dropout(p=0.2, inplace=False)
    (4): Linear(in_features=128, out_features=64, bias=True)
    (5): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): Dropout(p=0.2, inplace=False)
    (8): Linear(in_features=64, out_features=32, bias=True)
    (9): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): ReLU()
    (11): Dropout(p=0.2, inplace=False)
    (12): Linear(in_features=32, out_features=1, bias=True)
  )
)
###################-STARTED TRAINING-###################
TRAIN:	 Epoch:   1 | BCE Loss: 0.45869 
TRAIN:	 Epoch:   2 | BCE Loss: 0.45133 
TRAIN:	 Epoch:   3 | BCE Loss: 0.44854 
TRAIN:	 Epoch:   4 | BCE Loss: 0.44638 
TRAIN:	 Epoch:   5 | BCE Loss: 0.44424 
TRAIN:	 Epoch:   6 | BCE Loss: 0.44222 
TRAIN:	 Epoch:   7 | BCE Loss: 0.44004 
TRAIN:	 Epoch:   8 | BCE Loss: 0.43784 
TRAIN:	 Epoch:   9 | BCE Loss: 0.43599 
TRAIN:	 Epoch:  10 | BCE Loss: 0.43480 
###################-FINISHED TRAINING-###################
###################-STARTED TESTING-###################
TEST:	 BCE Loss: 0.45699 | ROC AUC: 0.57104 | Accuracy: 0.82866
###################-FINISHED TESTING-###################
