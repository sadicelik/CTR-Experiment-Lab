MODEL GENERATOR: PyTorch: DeepEmbed(
  (embedding): EmbeddingLayer(
    (embedding): Embedding(1396591, 16)
  )
  (mlp): MultiLayerPerceptronLayer(
    (mlp): Sequential(
      (0): Linear(in_features=352, out_features=512, bias=True)
      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.2, inplace=False)
      (4): Linear(in_features=512, out_features=256, bias=True)
      (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): ReLU()
      (7): Dropout(p=0.2, inplace=False)
      (8): Linear(in_features=256, out_features=128, bias=True)
      (9): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (10): ReLU()
      (11): Dropout(p=0.2, inplace=False)
      (12): Linear(in_features=128, out_features=1, bias=True)
    )
  )
)
###################-STARTED TRAINING-###################
TRAIN:	 Epoch:   1 | BCE Loss: 0.42110 
TRAIN:	 Epoch:   2 | BCE Loss: 0.40451 
TRAIN:	 Epoch:   3 | BCE Loss: 0.39898 
TRAIN:	 Epoch:   4 | BCE Loss: 0.39024 
TRAIN:	 Epoch:   5 | BCE Loss: 0.37587 
TRAIN:	 Epoch:   6 | BCE Loss: 0.35529 
TRAIN:	 Epoch:   7 | BCE Loss: 0.33078 
TRAIN:	 Epoch:   8 | BCE Loss: 0.30305 
TRAIN:	 Epoch:   9 | BCE Loss: 0.27355 
TRAIN:	 Epoch:  10 | BCE Loss: 0.24405 
###################-FINISHED TRAINING-###################
###################-STARTED TESTING-###################
TEST:	 BCE Loss: 0.79484 | ROC AUC: 0.44620 | Accuracy: 0.71108
###################-FINISHED TESTING-###################
